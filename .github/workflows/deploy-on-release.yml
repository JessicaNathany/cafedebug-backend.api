name: Deploy on Release

on:
  release:
    types: [published]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  deploy:
    name: Deploy to Prod
    runs-on: ubuntu-latest
    environment: production
    permissions:
      contents: read
      packages: read # REQUIRED to pull images from GHCR

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.release.target_commitish }}

      - name: Resolve image tag
        id: image
        run: |
          # Use the actual commit SHA from the checkout
          COMMIT_SHORT=$(echo ${{ github.sha }} | cut -c1-7)
          # Ensure this format matches what your CI pushes!
          # IMAGE_TAG="main-${COMMIT_SHORT}" this is temporarily commented out to match feature branch deployments
          IMAGE_TAG="feature-${COMMIT_SHORT}"
          
          echo "tag=${IMAGE_TAG}" >> $GITHUB_OUTPUT
          echo "Deploying image tag: ${IMAGE_TAG}"

      - name: Generate .env file
        run: |
          # Create .env on the runner temporarily
          cat > .env << EOF
          # Generated by GitHub Actions
          IMAGE_TAG=${{ steps.image.outputs.tag }}
          ASPNETCORE_ENVIRONMENT=Production
          
          # Caddy Configuration
          CADDY_DOMAIN=${{ vars.CADDY_DOMAIN }}
          
          # Database Configuration
          ConnectionStrings__CafedebugConnectionStringMySQL=${{ vars.DB_CONNECTION }}
          
          # JWT Configuration
          JwtSettings__Issuer=${{ vars.JWT_ISSUER }}
          JwtSettings__Audience=${{ vars.JWT_AUDIENCE }}
          JwtSettings__SigningKey=${{ vars.JWT_SIGNING_KEY }}
          JwtSettings__ValidForMinutes=15
          JwtSettings__RefreshTokenValidForMinutes=10080
          
          # AWS S3 Storage
          Storage__AWS__S3__Bucket=${{ vars.AWS_S3_BUCKET }}
          Storage__AWS__S3__Region=${{ vars.AWS_S3_REGION }}
          Storage__AWS__S3__BaseUrl=${{ vars.AWS_S3_BASE_URL }}
          Storage__AWS__S3__ServiceUrl=null
          Storage__AWS__S3__ForcePathStyle=false
          Storage__AWS__S3__UseHttp=false
          
          # Email/SMTP Configuration
          SMTP_SERVER=${{ vars.SMTP_SERVER }}
          SMTP_PORT=${{ vars.SMTP_PORT }}
          SMTP_USERNAME=${{ vars.SMTP_USERNAME }}
          SMTP_PASSWORD=${{ vars.SMTP_PASSWORD }}
          SMTP_FROM_EMAIL=${{ vars.SMTP_FROM_EMAIL }}
          SMTP_FROM_NAME=${{ vars.SMTP_FROM_NAME }}

          # Health Check Configuration
          HealthChecksUI__HealthChecks__0__Uri=http://cafedebug-stack_cafedebug-api:8080/health

          EOF
          chmod 600 .env
          
          # Validate .env was created
          if [ ! -f .env ]; then
            echo "ERROR: .env file was not created"
            exit 1
          fi
          echo "✓ .env file created successfully"

      - name: Test SSH Connectivity
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AWS_EC2_HOST }}
          username: ${{ vars.AWS_EC2_USER }}
          key: ${{ secrets.AWS_EC2_SSH_KEY }}
          port: ${{ vars.AWS_EC2_PORT }}
          script: |
            echo "=== SSH Connection Test ==="
            echo "Connected to: $(hostname)"
            echo "User: $(whoami)"
            echo "Home directory: $HOME"
            echo "Current directory: $(pwd)"
            echo "Checking target path..."
            echo "Target directory: ${{ vars.DOCKER_COMPOSE_PATH }}"
            
            # Check if we can create directories
            if [ -w "$(dirname ${{ vars.DOCKER_COMPOSE_PATH }})" ] || [ -w "${{ vars.DOCKER_COMPOSE_PATH }}" ]; then
              echo "✓ Write permission OK"
            else
              echo "✗ No write permission to ${{ vars.DOCKER_COMPOSE_PATH }}"
              exit 1
            fi
            
            # Check SSH key info
            echo "SSH connection successful!"

      - name: Prepare Remote Directory
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AWS_EC2_HOST }}
          username: ${{ vars.AWS_EC2_USER }}
          key: ${{ secrets.AWS_EC2_SSH_KEY }}
          port: ${{ vars.AWS_EC2_PORT }}
          script: |
            mkdir -p "${{ vars.DOCKER_COMPOSE_PATH }}/scripts"
            echo "Created directory: ${{ vars.DOCKER_COMPOSE_PATH }}/scripts"

      - name: Read files for transfer
        id: read_files
        run: |
          # Base64 encode files to avoid delimiter issues
          echo "env_b64=$(cat .env | base64 -w 0)" >> $GITHUB_OUTPUT
          echo "compose_b64=$(cat docker-compose.yml | base64 -w 0)" >> $GITHUB_OUTPUT
          echo "caddy_b64=$(cat Caddyfile | base64 -w 0)" >> $GITHUB_OUTPUT
          echo "deploy_b64=$(cat scripts/deploy.sh | base64 -w 0)" >> $GITHUB_OUTPUT
          echo "✓ Read and encoded all files for transfer"
      
      - name: Transfer files via SSH
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AWS_EC2_HOST }}
          username: ${{ vars.AWS_EC2_USER }}
          key: ${{ secrets.AWS_EC2_SSH_KEY }}
          port: ${{ vars.AWS_EC2_PORT }}
          script: |
            set -e
            TARGET="${{ vars.DOCKER_COMPOSE_PATH }}"
            
            # Decode and write .env file
            echo '${{ steps.read_files.outputs.env_b64 }}' | base64 -d > "$TARGET/.env"
            chmod 600 "$TARGET/.env"
            echo "✓ Copied .env"
            
            # Decode and write docker-compose.yml
            echo '${{ steps.read_files.outputs.compose_b64 }}' | base64 -d > "$TARGET/docker-compose.yml"
            echo "✓ Copied docker-compose.yml"
            
            # Decode and write Caddyfile
            echo '${{ steps.read_files.outputs.caddy_b64 }}' | base64 -d > "$TARGET/Caddyfile"
            echo "✓ Copied Caddyfile"
            
            # Decode and write deploy.sh
            echo '${{ steps.read_files.outputs.deploy_b64 }}' | base64 -d > "$TARGET/scripts/deploy.sh"
            chmod +x "$TARGET/scripts/deploy.sh"
            echo "✓ Copied and made deploy.sh executable"
            
            echo "All files transferred successfully!"

      - name: Execute Deployment
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AWS_EC2_HOST }}
          username: ${{ vars.AWS_EC2_USER }}
          key: ${{ secrets.AWS_EC2_SSH_KEY }}
          port: ${{ vars.AWS_EC2_PORT }}
          script: |
            set -e
            cd "${{ vars.DOCKER_COMPOSE_PATH }}"
            
            # Verify files were copied
            echo "Checking copied files..."
            ls -lah .env docker-compose.yml Caddyfile scripts/deploy.sh
            
            # Login to Registry
            echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
            
            # Run the deploy script
            # We pass the tag, but the script also loads it from .env (redundancy is fine)
            bash scripts/deploy.sh "${{ steps.image.outputs.tag }}"

            # Logout from registry 
            docker logout ghcr.io
            
      - name: Verify Deployment
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AWS_EC2_HOST }}
          username: ${{ vars.AWS_EC2_USER }}
          key: ${{ secrets.AWS_EC2_SSH_KEY }}
          port: ${{ vars.AWS_EC2_PORT }}
          script: |
            set -e
            cd "${{ vars.DOCKER_COMPOSE_PATH }}"
            
            echo "Verifying deployment..."
            
            # Check service status
            docker service ls | grep cafedebug-stack
            
            # Check running replicas
            REPLICAS=$(docker service ls --filter name=cafedebug-stack_cafedebug-api --format "{{.Replicas}}")
            echo "API Replicas: $REPLICAS"
            
            # Show recent logs (last 20 lines)
            echo "Recent logs:"
            docker service logs --tail 20 cafedebug-stack_cafedebug-api || true
            
            echo "✓ Deployment verification complete"        